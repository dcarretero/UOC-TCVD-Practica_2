---
title: "Practica 2"
author: "Tipologia y Ciclo de Vida De Los Datos"
date: "Diciembre 2021"
output:
  word_document:
    toc: yes
    toc_depth: '2'
  html_document:
    number_sections: no
    toc: yes
    toc_depth: 2
  pdf_document:
    number_section: no
    toc: yes
    latex_engine: xelatex
lang: es
---

******
# 0- Carga de librerias
******
> Antes de empezar cargamos todas las librerías necesarias.

```{r include=FALSE}
# https://cran.r-project.org/web/packages/DataExplorer/index.html
if(!require(DataExplorer)){
    install.packages('DataExplorer', repos='http://cran.us.r-project.org')
    library(DataExplorer)
}

if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
# https://cran.r-project.org/web/packages/skimr/index.html
if (!require('skimr')) install.packages('skimr'); library ('skimr')
# https://cran.r-project.org/web/packages/corrplot/index.html
if (!require('corrplot')) install.packages('corrplot'); library('corrplot')
# https://cran.r-project.org/web/packages/nortest/index.html
if (!require('nortest')) install.packages('nortest'); library ('nortest')
# https://cran.r-project.org/web/packages/stats/index.html
if (!require('stats')) install.packages('stats'); library('stats')
# https://cran.r-project.org/web/packages/faraway/index.html
if (!require('faraway')) install.packages('faraway'); library('faraway')
# https://cran.r-project.org/web/packages/ResourceSelection/index.html
if (!require('ResourceSelection')) install.packages('ResourceSelection'); library('ResourceSelection')
# https://cran.r-project.org/web/packages/pROC/index.html
if (!require('pROC')) install.packages('pROC'); library('pROC')
# https://cran.r-project.org/web/packages/factoextra/index.html
if (!require('factoextra')) install.packages('factoextra'); library('factoextra')
if(!require(C50)){
    install.packages('C50',repos='http://cran.es.r-project.org')
    require(C50)
}
if(!require('klaR')) install.packages('klaR', repos='http://cran.us.r-project.org');library('klaR')
if(!require('kernlab')) install.packages('kernlab', repos='http://cran.us.r-project.org');library('kernlab')
if(!require('caret')) install.packages('caret', repos='http://cran.us.r-project.org');library('caret')
if(!require('xgboost')) install.packages('xgboost',repos='http://cran.us.r-project.org');library('xgboost')
if(!require('arules')) install.packages('arules', repos='http://cran.us.r-project.org');library('arules')


```

******
# 1- Descripción del dataset
******

> Nuestra selección del dataset es: Red Wine Quality de.

> * https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009

> Tenemos dos conjuntos de datos que están relacionados con variantes tinto y blanco del vino portugués "Vinho Verde".

> Ambos datasets contienen 12 variables númericas:

> * **fixed.acidity**: el nivel de la acidez fija.
  * **volatile.acidity**: el nivel de la acidez volátil.
  * **citric.acid**: el nivel del ácido cítrico.
  * **residual.sugar**: el nivel del azúcar residual.
  * **chlorides**: el nivel de los cloruros.
  * **free.sulfur.dioxide**: el nivel del dióxido de azufre libre.
  * **total.sulfur.dioxide**: el nivel del dióxido de azufre total.
  * **density**: el nivel de la densidad.
  * **pH**: el nivel del pH.
  * **sulphates**: el nivel de los sulfatos.
  * **alcohol**: el nivel del alcohol.
  * **quality**: la calidad (entre 0 y 9).

> La pregunta que nos planteamos gira entorno a las propiedades y calidad del vino (incluye la comparativa entre diferentes tipos de vinos): 

> * ¿Qué propiedades fisicoquímicas hacen que un vino (tinto y/o blanco) sea bueno?



******
# 2- Integración y selección de los datos de interés
******

> Nuestra propuesta pasa por integrar ambos datasets en uno nuevo `dt_winequality` que contenga una nueva variable para determinar si el vino es tinto o blanco.

> Primero realizamos la carga del archivos de datos `winequality-red.csv` y añadimos una nueva variable `type` con valor `red`.

```{r}
dt_red_wines<-read.csv("../datasets/winequality-red.csv", header=T, sep=";")
type<-"red"
dt_red_wines<-cbind(type, dt_red_wines)
```

> A continuación realizamos la carga del archivos de datos `winequality-white.csv` y añadimos también la variable `type` esta vez con valor `white`.

```{r}
dt_white_wines<-read.csv("../datasets/winequality-white.csv", header=T, sep=";")
type<-"white"
dt_white_wines<-cbind(type, dt_white_wines)
```

> Con las funciones `dim()` y `str()` comparamos las dimensiones de los conjuntos de datos y sus estructuras antes de realizar la integración de ambos datasets.

```{r}
dim(dt_red_wines)
str(dt_red_wines)
dim(dt_white_wines)
str(dt_white_wines)
```

> Los resultados nos muestran que ambos datasets contienen 13 variables contínuas y que el dataset de los vinos blancos es hasta tres veces más grande que el dataset de los vinos rojos.

```{r}
dt_winequality<-rbind(dt_red_wines, dt_white_wines)
dim(dt_winequality)
```

> Los resultados muestran que los datos (6497 observaciones y 13 variables) se han integrado correctamente.

******
# 3- Limpieza de datos
******

## 3.1 - Valores perdidos

> Las funciones `introduce(dt_winequality)` y `plot_intro(dt_winequality)` describen la información básica para los datos de entrada.

```{r}
introduce(dt_winequality)
plot_intro(dt_winequality)
```

> Observamos que no hay valores perdidos.

## 3.2 - Identificación y tratamiento de valores extremos

> Diagrama de caja para la variable `fixed.acidity`.

```{r}
boxplot(dt_winequality$fixed.acidity, main="fixed.acidity", names=c("red & white"))
```

> Utilizamos la función `boxplot.stats()` con coeficiente 3 para calcular el lower y upper whiskers.

```{r}
box_plot_results<-boxplot.stats(dt_winequality$fixed.acidity, coef = 3)
boxplot.stats(dt_winequality$fixed.acidity, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]
```

> Imputamos los valores lower y upper whiskers si nuestros valores extremos son inferiores o superiores respectivamente.

```{r}
dt_winequality$fixed.acidity[which(dt_winequality$fixed.acidity < lower_whisker)]<-lower_whisker
dt_winequality$fixed.acidity[which(dt_winequality$fixed.acidity > upper_whisker)]<-upper_whisker
```

> Se aplica este mismo tratamiento al resto de variables explicativas.

```{r include=FALSE}
# Cálculo para la variable volatile.acidity
boxplot(dt_winequality$volatile.acidity, main="volatile.acidity", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$volatile.acidity, coef = 3)
boxplot.stats(dt_winequality$volatile.acidity, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$volatile.acidity[which(dt_winequality$volatile.acidity < lower_whisker)]<-lower_whisker
dt_winequality$volatile.acidity[which(dt_winequality$volatile.acidity > upper_whisker)]<-upper_whisker
```

```{r include=FALSE}
# Cálculo para la variable citric.acid
boxplot(dt_winequality$citric.acid, main="citric.acid", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$citric.acid, coef = 3)
boxplot.stats(dt_winequality$citric.acid, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$citric.acid[which(dt_winequality$citric.acid < lower_whisker)]<-lower_whisker
dt_winequality$citric.acid[which(dt_winequality$citric.acid > upper_whisker)]<-upper_whisker
```

```{r include=FALSE}
# Cálculo para la variable residual.sugar
boxplot(dt_winequality$residual.sugar, main="residual.sugar", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$residual.sugar, coef = 3)
boxplot.stats(dt_winequality$residual.sugar, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$residual.sugar[which(dt_winequality$residual.sugar < lower_whisker)]<-lower_whisker
dt_winequality$residual.sugar[which(dt_winequality$residual.sugar > upper_whisker)]<-upper_whisker
```


```{r include=FALSE}
# Cálculo para la variable chlorides
boxplot(dt_winequality$chlorides, main="chlorides", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$chlorides, coef = 3)
boxplot.stats(dt_winequality$chlorides, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$chlorides[which(dt_winequality$chlorides < lower_whisker)]<-lower_whisker
dt_winequality$chlorides[which(dt_winequality$chlorides > upper_whisker)]<-upper_whisker
```

```{r include=FALSE}
# Cálculo para la variable free.sulfur.dioxide
boxplot(dt_winequality$free.sulfur.dioxide, main="free.sulfur.dioxide", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$free.sulfur.dioxide, coef = 3)
boxplot.stats(dt_winequality$free.sulfur.dioxide, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$free.sulfur.dioxide[which(dt_winequality$free.sulfur.dioxide < lower_whisker | dt_winequality$free.sulfur.dioxide > upper_whisker)] <- mean(dt_winequality$free.sulfur.dioxide, na.rm = TRUE)
```

```{r include=FALSE}
# Cálculo para la variable total.sulfur.dioxide
boxplot(dt_winequality$total.sulfur.dioxide, main="total.sulfur.dioxide", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$total.sulfur.dioxide, coef = 3)
boxplot.stats(dt_winequality$total.sulfur.dioxide, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$total.sulfur.dioxide[which(dt_winequality$total.sulfur.dioxide < lower_whisker)]<-lower_whisker
dt_winequality$total.sulfur.dioxide[which(dt_winequality$total.sulfur.dioxide > upper_whisker)]<-upper_whisker
```

```{r include=FALSE}
# Cálculo para la variable density
boxplot(dt_winequality$density, main="density", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$density, coef = 3)
boxplot.stats(dt_winequality$density, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$density[which(dt_winequality$density < lower_whisker)]<-lower_whisker
dt_winequality$density[which(dt_winequality$density > upper_whisker)]<-upper_whisker
```

```{r include=FALSE}
# Cálculo para la variable pH
boxplot(dt_winequality$pH, main="pH", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$pH, coef = 3)
boxplot.stats(dt_winequality$pH, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$pH[which(dt_winequality$pH < lower_whisker)]<-lower_whisker
dt_winequality$pH[which(dt_winequality$pH > upper_whisker)]<-upper_whisker
```

```{r include=FALSE}
# Cálculo para la variable sulphates
boxplot(dt_winequality$sulphates, main="sulphates", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$sulphates, coef = 3)
boxplot.stats(dt_winequality$sulphates, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$sulphates[which(dt_winequality$sulphates < lower_whisker)]<-lower_whisker
dt_winequality$sulphates[which(dt_winequality$sulphates > upper_whisker)]<-upper_whisker
```

```{r include=FALSE}
# Cálculo para la variable alcohol
boxplot(dt_winequality$alcohol, main="alcohol", names=c("red & white"))

box_plot_results<-boxplot.stats(dt_winequality$alcohol, coef = 3)
boxplot.stats(dt_winequality$alcohol, coef = 3)

lower_whisker<-box_plot_results$stats[1]
upper_whisker<-box_plot_results$stats[5]

dt_winequality$alcohol[which(dt_winequality$alcohol < lower_whisker)]<-lower_whisker
dt_winequality$alcohol[which(dt_winequality$alcohol > upper_whisker)]<-upper_whisker
```

```{r include=FALSE}
boxplot(dt_winequality$quality, main="quality", names=c("red & white"))
```

******
# 4- Análisis de datos
******

## 4.1 - Selección del grupo de datos que se quiere analizar

### 4.1.1 - Correlación de variables 

> Se mira la correlación entre variables explicativas para ver si es descartable alguna de ellas.

```{r}
dt_winequality.corr <- dt_winequality %>% dplyr::select(!c(quality,type))
dt_winequality.mat.corr <- cor(dt_winequality.corr,method =  "pearson", use="pairwise.complete.obs")
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD","#4477AA"))


corrplot(dt_winequality.mat.corr, type="upper", method = "shade", shade.col = NA, tl.col = "black", tl.srt = 45, col = col(50), addCoef.col="black",order="AOE",mar = c(0.0001,1,1,1), number.cex=0.5,cl.cex = 0.7,tl.cex = 0.7, title = " Matriz de correlación")
```

> Las correlaciones mas altas son:

 * densidad con alcohol (-0.69)
 * free.sulfur.dioxide con tota.sulfur.dioxide (0.72)

> Aún siendo altas ambas correlaciones, se decide mantener estas variables en el modelado.  En caso de haber habido un conjunto mayor de variables explicativas, estas variables correlacionadas hubiesen sido las primeras candidatas a eliminarse del modelo, pero el no tener unos valores mas próximos a 1 y el hecho de no tener excesivas variables explicativas se ha optado por mantenerlas.

> En este caso se va a optar por utilizar todas las variables explicativas numéricas en los diferentes modelos predictivos que se realicen. La variable explicativa "type" solo va a ser utilizada en el contraste de hipotesis para ver si hay una diferencia en la media de calidad por tipo de vino.
La variable de respuestas seleccionada es "quality" y es aquella para que se va entrenar el modelo predictivo.

> Por último comentar que se va a generar una variable dicotimica a partir de la variable de calidad. Esta variable "quality_class" permitirá clasificar el vino y hacer algoritmos predictivos sobre una variable de respuesta categorica.

```{r}
dt_winequality<-mutate(dt_winequality, quality_class = ifelse(quality >=7 , "good", "not good"))
dt_winequality$quality_class<-as.factor(dt_winequality$quality_class)
```

### 4.1.2 - Reducción de la dimensionalidad (PCA)

>Se aplica el algoritmo PCA para obtener las componentes principales y plantear una reducción de la dimensionalidad del problema.


```{r}
pca<- prcomp(dt_winequality.corr,scale=TRUE)

```

> El aporte de cada una de las variables a las componentes principales es el siguiente:

```{r}
pca$rotation
```

> Las desviaciones standard de cada una de las componentes principales puede ser obtenida del siguiente modo:

```{r}
pca$sdev
```
> A partir de las desviaciones standard se obtienen las varianzas y se divide por la suma de varianzas para obtener la proporcion de varianza que aportan cada una de las componentes principales. 

```{r}
prop_varianza <- pca$sdev^2 / sum(pca$sdev^2)
prop_varianza
```

> Se representa de manera gráfica el aporte de las diez componentes principales a la varianza:

```{r}
fviz_eig(pca,xlab="Componente principal",ylab="Porcentaje de varianza explicada",main="",ncp=10)
```

> También se representa de manera gráfica la descomposición de cada una de las variables predictoras en las dos componentes principales:

```{r}
fviz_pca_var(pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```

> Se calcula la proporción de varianza acumulada de las componentes principales:

```{r}
prop_varianza_acum <- cumsum(prop_varianza)
prop_varianza_acum

```


> Se hace una representación gráfica de la proporción de varianza acumulada que muestra a partir de que componente principal se vuelve despreciable el aporte de una nueva componente principal. Ya en los datos anteriores se observaba que a partir de la sexta componente principal ya se había realizado mas de un 98% del aporte y ahora se ve expresado de manera gráfica.

```{r}
ggplot(data = data.frame(prop_varianza_acum, pc = 1:11),
       aes(x = pc, y = prop_varianza_acum, group = 1)) +
  geom_point() +
  geom_line() +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. varianza explicada acumulada")
```

> Tras estudio de las componentes principales se llega a la conclusión para explicar un grado importante de la varianza p.e. un 80% se necesitaría hasta 6 componentes principales. Además se observa que el aporte de cada una de las variables explicativas a las componentes principales está muy distribuido. Debido al reducido numero de variables explicativas y a lo distribuida que está la varianza entre ellas se decide mantener todas ellas en la obtención de un modelo supervisado.


## 4.2 - Comprobación de la normalidad y homogeneidad de la varianza

> Se va a trabajar para el contraste de hipotesis con las medias muestrales, con lo cual al ser una muestra mayor de 30 elementos puede aplicarse el teorema del limite central bajo el cual se supone que dichas medias muestrales siguen una distribución normal.
En cuanto a la homogeneidad de la varianza de la variable de respuesta "quality" entre el conjunto de vinos tintos y blancos se observa que las varianzas de ambos grupos no puede descartarse la hipotesis nula de que sean varianzas iguales al dar un valor de F que se encuentra dentro del intervalo de confianza.

```{r}

var.test(dt_red_wines$quality,dt_white_wines$quality)
```



## 4.3 - Pruebas estadísticas

### 4.3.1 - Contraste de hipotesis
> Se realiza un contraste de hipotesis sobre de las medias de calidad de vino blanco y tinto para ver si son iguales o diferentes.

H0: \(\mu_{red} = \mu_{white}\)

H1: \(\mu_{red} \neq \mu_{white}\)

> Se trata de un contraste de dos muestras de varianzas desconocidas, pero iguales. Esto implica aplicar T-test para la realización del contraste de hipótesis.

```{r}
t.test(dt_red_wines$quality,dt_white_wines$quality,alternative="two.sided", var.equal=TRUE)

```

>Se puede observar que realmente hay una diferencia en las medias de calidad entre tipos de vino al ser el p-value mucho menor que el valor de significancia de 0.05 y ser por tanto rechazable la hipotesis nula. Las medias de calidad del vino tinto y del blanco son significativamente diferentes desde un punto de vista estadístico.

### 4.3.2 - Modelado y evaluación de algoritmos Predictivos 


#### 4.3.2.1 - Partición en conjuntos de entrenamiento y test 
```{r}
set.seed(3456)
trainIndex <- createDataPartition(dt_winequality$quality_class, p = .7, 
                                  list = FALSE, 
                                  times = 1)

dt_winequality.data.train <-dt_winequality[trainIndex,]%>%dplyr::select(-c(quality))
dt_winequality.data.test  <- dt_winequality[-trainIndex,]%>%dplyr::select(-c(quality))
```

#### 4.3.2.2 - Tuning básico de parametros configurando cross-validation
```{r}
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)
```


#### 4.3.2.3. - Obtención de modelos 

#### 4.3.2.3.1 -  CART

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}


modelRPART <- train(quality_class ~ ., data = dt_winequality.data.train, 
                 method = "rpart", 
                 trControl = fitControl)
```


#### 4.3.2.3.2 -  KNN

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=TRUE}


modelKNN<- train(quality_class ~ ., data = dt_winequality.data.train, 
                 method = "knn", 
                 trControl = fitControl)

modelKNN
```
#### 4.3.2.3.2 -  GENERALIZED LINEAR MODEL

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=TRUE}


modelGLM<- train(quality_class ~ ., data = dt_winequality.data.train, 
                 method = "glm", 
                 trControl = fitControl)

modelGLM
```

#### 4.3.2.3. - Comparativa de modelos

> Para comparar los diferentes modelos, al habarse obtenido todos a partir del paquete Caret se puede usar la función resamples

```{r}
results <- resamples(list(RPART=modelRPART, KNN=modelKNN, GLM=modelGLM))
# summarize the distributions
summary(results)

```
```{r}
# boxplots of results
bwplot(results)

```


```{r}
# dot plots of results
dotplot(results)
```

Por lo que se puede observar el mejor modelo parece ser el GLM, aunque si se quisiera ver de una manera mas purista si las diferencias mostradas son estadisticamente significativas se debería hacer un contraste de hipotesis entre ellas. 


### 4.3.3. Prediccion con algoritmo GLM seleccionado sobre el conjunto de test
```{r}
dt_winequality.data.test.X<-dt_winequality.data.test%>%dplyr::select(-c(quality_class))
dt_winequality.data.test.Y<-as.factor((dt_winequality.data.test%>%dplyr::select(c(quality_class)))$quality_class)
predicted_GLM<- predict(modelGLM, dt_winequality.data.test.X)
```


### 4.3.4 - Matriz confusión
```{r}
confusionMatrix(reference = dt_winequality.data.test.Y, data = predicted_GLM, mode='everything', positive='good')
```

### 4.3.5. ROC y AUC
```{r}
plot.roc(as.numeric(predicted_GLM),as.numeric(dt_winequality.data.test.Y),print.auc=TRUE)

```

******
# 5- Representación de los resultados
******

TO DO

******
# 6- Resolución del problema
******

TO DO