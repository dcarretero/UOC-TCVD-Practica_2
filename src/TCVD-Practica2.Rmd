---
title: "Practica 2"
author: "Tipologia y Ciclo de Vida De Los Datos"
date: "Diciembre 2021"
output:
  html_document:
    number_sections: no
    toc: yes
    toc_depth: 2
  pdf_document: 
    number_section: no
    toc: yes
    latex_engine: xelatex
lang: es
---

******
# 0- Carga de librerias
******
> Antes de empezar cargamos todas las librerías necesarias.

```{r}
# https://cran.r-project.org/web/packages/DataExplorer/index.html
if(!require(DataExplorer)){
    install.packages('DataExplorer', repos='http://cran.us.r-project.org')
    library(DataExplorer)
}

if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
# https://cran.r-project.org/web/packages/skimr/index.html
if (!require('skimr')) install.packages('skimr'); library ('skimr')
# https://cran.r-project.org/web/packages/corrplot/index.html
if (!require('corrplot')) install.packages('corrplot'); library('corrplot')
# https://cran.r-project.org/web/packages/nortest/index.html
if (!require('nortest')) install.packages('nortest'); library ('nortest')
# https://cran.r-project.org/web/packages/stats/index.html
if (!require('stats')) install.packages('stats'); library('stats')
# https://cran.r-project.org/web/packages/faraway/index.html
if (!require('faraway')) install.packages('faraway'); library('faraway')
# https://cran.r-project.org/web/packages/ResourceSelection/index.html
if (!require('ResourceSelection')) install.packages('ResourceSelection'); library('ResourceSelection')
# https://cran.r-project.org/web/packages/pROC/index.html
if (!require('pROC')) install.packages('pROC'); library('pROC')

# https://cran.r-project.org/web/packages/factoextra/index.html
if (!require('factoextra')) install.packages('factoextra'); library('factoextra')

if(!require(C50)){
    install.packages('C50',repos='http://cran.es.r-project.org')
    require(C50)
}
if(!require('caret')) install.packages('caret', repos='http://cran.us.r-project.org');library('caret')
if(!require('xgboost')) install.packages('xgboost',repos='http://cran.us.r-project.org');library('xgboost')
if(!require('arules')) install.packages('arules', repos='http://cran.us.r-project.org');library('arules')
```

******
# 1- Descripción del dataset
******

> Nuestra selección del dataset es: Red Wine Quality de.

> * https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009

> Tenemos dos conjuntos de datos que están relacionados con variantes tinto y blanco del vino portugués "Vinho Verde".

> Ambos datasets contienen 12 variables númericas:

> * **fixed.acidity**: el nivel de la acidez fija.
  * **volatile.acidity**: el nivel de la acidez volátil.
  * **citric.acid**: el nivel del ácido cítrico.
  * **residual.sugar**: el nivel del azúcar residual.
  * **chlorides**: el nivel de los cloruros.
  * **free.sulfur.dioxide**: el nivel del dióxido de azufre libre.
  * **total.sulfur.dioxide**: el nivel del dióxido de azufre total.
  * **density**: el nivel de la densidad.
  * **pH**: el nivel del pH.
  * **sulphates**: el nivel de los sulfatos.
  * **alcohol**: el nivel del alcohol.
  * **quality**: la calidad.

> La pregunta que nos planteamos gira entorno a las propiedades y calidad del vino (incluye la comparativa entre diferentes tipos de vinos): 

> * ¿Qué propiedades fisicoquímicas hacen que un vino (tinto y/o blanco) sea bueno?



******
# 2- Integración y selección de los datos de interés
******

> Nuestra propuesta pasa por integrar ambos datasets en uno nuevo `dt_winequality` que contenga una nueva variable para determinar si el vino es tinto o blanco.

> Primero realizamos la carga del archivos de datos `winequality-red.csv` y añadimos una nueva variable `type` con valor `red`.

```{r}
dt_red_wines<-read.csv("../datasets/winequality-red.csv", header=T, sep=";")
type<-"red"
dt_red_wines<-cbind(type, dt_red_wines)
```

> A continuación realizamos la carga del archivos de datos `winequality-white.csv` y añadimos también la variable `type` esta vez con valor `white`.

```{r}
dt_white_wines<-read.csv("../datasets/winequality-white.csv", header=T, sep=";")
type<-"white"
dt_white_wines<-cbind(type, dt_white_wines)
```

> Con las funciones `dim()` y `str()` comparamos las dimensiones de los conjuntos de datos y sus estructuras antes de realizar la integración de ambos datasets.

```{r}
dim(dt_red_wines)
str(dt_red_wines)
dim(dt_white_wines)
str(dt_white_wines)
```

> Los resultados nos muestran que ambos datasets contienen 13 variables contínuas y que el dataset de los vinos blancos es hasta tres veces más grande que el dataset de los vinos rojos.

```{r}
dt_winequality<-rbind(dt_red_wines, dt_white_wines)
dim(dt_winequality)
```

> Los resultados muestran que los datos (6497 observaciones y 13 variables) se han integrado correctamente.


```{r}
skimr::skim(dt_winequality)
```
******
# 3- Limpieza de datos
******

## 3.1 - Valores perdidos

> Las funciones `introduce(dt_winequality)` y `plot_intro(dt_winequality)` describen la información básica para los datos de entrada.

```{r}
introduce(dt_winequality)
plot_intro(dt_winequality)
```

> Observamos que no hay valores perdidos.

## 3.2 - Identificación y tratamiento de valores extremos

> Diagrama de caja para la variable `fixed.acidity`.

```{r}
boxplot(dt_winequality$fixed.acidity, main="fixed.acidity", names=c("red & white"))
boxplot.stats(dt_winequality$fixed.acidity, coef = 3)
```

> Diagrama de caja para la variable `volatile.acidity`.

```{r}
boxplot(dt_winequality$volatile.acidity, main="volatile.acidity", names=c("red & white"))
boxplot.stats(dt_winequality$volatile.acidity, coef = 3)
```

> Diagrama de caja para la variable `citric.acid`.

```{r}
boxplot(dt_winequality$citric.acid, main="citric.acid", names=c("red & white"))
boxplot.stats(dt_winequality$citric.acid, coef = 3)
```

> Diagrama de caja para la variable `residual.sugar`.

```{r}
boxplot(dt_winequality$residual.sugar, main="residual.sugar", names=c("red & white"))
boxplot.stats(dt_winequality$residual.sugar, coef = 3)
```

> Diagrama de caja para la variable `chlorides`.

```{r}
boxplot(dt_winequality$chlorides, main="chlorides", names=c("red & white"))
boxplot.stats(dt_winequality$chlorides, coef = 3)
```

> Diagrama de caja para la variable `free.sulfur.dioxide`.

```{r}
boxplot(dt_winequality$free.sulfur.dioxide, main="free.sulfur.dioxide", names=c("red & white"))
boxplot.stats(dt_winequality$free.sulfur.dioxide, coef = 3)
```

> Diagrama de caja para la variable `total.sulfur.dioxide`.

```{r}
boxplot(dt_winequality$total.sulfur.dioxide, main="total.sulfur.dioxide", names=c("red & white"))
boxplot.stats(dt_winequality$total.sulfur.dioxide, coef = 3)
```

> Diagrama de caja para la variable `density`.

```{r}
boxplot(dt_winequality$density, main="density", names=c("red & white"))
boxplot.stats(dt_winequality$density, coef = 3)
```

> Diagrama de caja para la variable `pH`.

```{r}
boxplot(dt_winequality$pH, main="pH", names=c("red & white"))
boxplot.stats(dt_winequality$pH, coef = 3)
```

> Diagrama de caja para la variable `sulphates`.

```{r}
boxplot(dt_winequality$sulphates, main="sulphates", names=c("red & white"))
boxplot.stats(dt_winequality$sulphates, coef = 3)
```

> Diagrama de caja para la variable `alcohol`.

```{r}
boxplot(dt_winequality$alcohol, main="alcohol", names=c("red & white"))
boxplot.stats(dt_winequality$alcohol, coef = 3)
```

> Diagrama de caja para la variable `quality`.

```{r}
boxplot(dt_winequality$quality, main="quality", names=c("red & white"))
```

******
# 4- Análisis de datos
******

## 4.1 - Selección del grupo de datos que se quiere analizar

### 4.1.1 - Correlación de variables 

> Se mira la correlación entre variables explicativas para ver si es descartable alguna de ellas.

```{r}
dt_winequality.corr <-dt_winequality%>%select(-c(quality,type))
dt_winequality.mat.corr <- cor(dt_winequality.corr,method =  "pearson", use="pairwise.complete.obs")
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD","#4477AA"))


corrplot(dt_winequality.mat.corr, type="upper", method = "shade", shade.col = NA, tl.col = "black", tl.srt = 45, col = col(50), addCoef.col="black",order="AOE",mar = c(0.0001,1,1,1), number.cex=0.5,cl.cex = 0.7,tl.cex = 0.7, title = " Matriz de correlación")
```

> Las correlaciones mas altas son:

 * densidad con alcohol (-0.69)
 * free.sulfur.dioxide con tota.sulfur.dioxide (0.72)

> Aún siendo altas ambas correlaciones, se decide mantener estas variables en el modelado.  En caso de haber habido un conjunto mayor de variables explicativas, estas variables correlacionadas hubiesen sido las primeras candidatas a eliminarse del modelo, pero el no tener unos valores mas próximos a 1 y el hecho de no tener excesivas variables explicativas se ha optado por mantenerlas.

> En este caso se va a optar por utilizar todas las variables explicativas numéricas en los diferentes modelos predictivos que se realicen. La variable explicativa "type" solo va a ser utilizada en el contraste de hipotesis para ver si hay una diferencia en la media de calidad por tipo de vino.
La variable de respuestas seleccionada es "quality" y es aquella para que se va entrenar el modelo predictivo.

> Por último comentar que se va a generar una variable dicotimica a partir de la variable de calidad. Esta variable "quality_class" permitirá clasificar el vino y hacer algoritmos predictivos sobre una variable de respuesta categorica.

```{r}
dt_winequality<-mutate(dt_winequality, quality_class = ifelse(quality >=7 , "good", "not good"))
```

### 4.1.2 - Reducción de la dimensionalidad (PCA)

>Se aplica el algoritmo PCA para obtener las componentes principales y plantear una reducción de la dimensionalidad del problema.


```{r}
pca<- prcomp(dt_winequality.corr,scale=TRUE)

```

> El aporte de cada una de las variables a las componentes principales es el siguiente:
```{r}
pca$rotation
```
> Las desviaciones standard de cada una de las componentes principales puede ser obtenida del siguiente modo:

```{r}
pca$sdev
```
> A partir de las desviaciones standard se obtienen las varianzas y se divide por la suma de varianzas para obtener la proporcion de varianza que aportan cada una de las componentes principales. 
```{r}
prop_varianza <- pca$sdev^2 / sum(pca$sdev^2)
prop_varianza
```

> Se representa de manera gráfica el aporte de las diez componentes principales a la varianza:

```{r}
fviz_eig(pca,xlab="Componente principal",ylab="Porcentaje de varianza explicada",main="",ncp=10)
```

> También se representa de manera gráfica la descomposición de cada una de las variables predictoras en las dos componentes principales:

```{r}
fviz_pca_var(pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```

> Se calcula la proporción de varianza acumulada de las componentes principales:
```{r}
prop_varianza_acum <- cumsum(prop_varianza)
prop_varianza_acum
```

> Se hace una representación gráfica de la proporción de varianza acumulada que muestra a partir de que componente principal se vuelve despreciable el aporte de una nueva componente principal. Ya en los datos anteriores se observaba que a partir de la sexta componente principal ya se había realizado mas de un 98% del aporte y ahora se ve expresado de manera gráfica.

```{r}
ggplot(data = data.frame(prop_varianza_acum, pc = 1:11),
       aes(x = pc, y = prop_varianza_acum, group = 1)) +
  geom_point() +
  geom_line() +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. varianza explicada acumulada")
```

> Tras estudio de las componentes principales se llega a la conclusión para explicar un grado importante de la varianza p.e. un 80% se necesitaría hasta 6 componentes principales. Además se observa que el aporte de cada una de las variables explicativas a las componentes principales está muy distribuido. Debido al reducido numero de variables explicativas y a lo distribuida que está la varianza entre ellas se decide mantener todas ellas en la obtención de un modelo supervisado.


## 4.2 - Comprobación de la normalidad y homogeneidad de la varianza

> Se va a trabajar para el contraste de hipotesis con las medias muestrales, con lo cual al ser una muestra mayor de 30 elementos puede aplicarse el teorema del limite central bajo el cual se supone que dichas medias muestrales siguen una distribución normal.
En cuanto a la homogeneidad de la varianza de la variable de respuesta "quality" entre el conjunto de vinos tintos y blancos se observa que las varianzas de ambos grupos no puede descartarse la hipotesis nula de que sean varianzas iguales al dar un valor de F que se encuentra dentro del intervalo de confianza.

```{r}

var.test(dt_red_wines$quality,dt_white_wines$quality)
```



## 4.3 - Pruebas estadísticas

### 4.3.1 - Contraste de hipotesis
> Se realiza un contraste de hipotesis sobre de las medias de calidad de vino blanco y tinto para ver si son iguales o diferentes.

H0: \(\mu_{red} = \mu_{white}\)

H1: \(\mu_{red} \neq \mu_{white}\)

> Se trata de un contraste de dos muestras de varianzas desconocidas, pero iguales. Esto implica aplicar T-test para la realización del contraste de hipótesis.

```{r}
t.test(dt_red_wines$quality,dt_white_wines$quality,alternative="two.sided", var.equal=TRUE)

```

>Se puede observar que realmente hay una diferencia en las medias de calidad entre tipos de vino al ser el p-value mucho menor que el valor de significancia de 0.05 y ser por tanto rechazable la hipotesis nula. Las medias de calidad del vino tinto y del blanco son significativamente diferentes desde un punto de vista estadístico.

### 4.3.2 - Modelado y evaluación de algoritmos Predictivos 

#### 4.3.2.1 - Con variable respuesta categórica

##### 4.3.2.1.1 - Partición en conjuntos de entrenamiento y test 
```{r}
set.seed(3456)
trainIndex <- createDataPartition(dt_winequality$quality_class, p = .7, 
                                  list = FALSE, 
                                  times = 1)

dt_winequality.data.train <- dt_winequality[ trainIndex,]
dt_winequality.data.test  <- dt_winequality[-trainIndex,]
```

##### 4.3.2.1.2 - Modelado y evaluación C50

> Se obtiene el modelo C50 con poda a partir del conjunto de entrenamiento

```{r}

dt_winequality.data.train.X<-dt_winequality.data.train%>%select(-c(quality,type,quality_class))
dt_winequality.data.train.Y<-as.factor(dt_winequality.data.train$quality_class)
model.C50 <- C50::C5.0(dt_winequality.data.train.X,dt_winequality.data.train.Y)
#summary(model.C50)

```

> Se evalua la precisión del modelo C50 sobre el conjunto de test

```{r}


dt_winequality.data.test.X<-dt_winequality.data.test%>%select(-c(quality,type,quality_class))
dt_winequality.data.test.Y<-as.factor(dt_winequality.data.test$quality_class)
predicted_model <- predict(model.C50, dt_winequality.data.test.X, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == dt_winequality.data.test.Y) / length(predicted_model)))
```

> Se repite el proceso de obtención del modelo, pero ahora sin poda

```{r}
model.C50.no.prune <- C50::C5.0(dt_winequality.data.train.X,dt_winequality.data.train.Y,control=C5.0Control(noGlobalPruning=TRUE))
# summary(model.C50.no.prune)


```

> Se evalua evalua la precisión del modelo sin poda sobre el conjunto de test y se observa que se obtiene una precisión ligeramente menor.

```{r}

predicted_model <- predict(model.C50.no.prune, dt_winequality.data.test.X, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == dt_winequality.data.test.Y) / length(predicted_model)))

```

##### 4.3.2.2.3 - Otro modelo??????

##### 4.3.2.2.3 - Comparativa de modelos

#### 4.3.2.2 - Con variable respuesta numérica
##### 4.3.2.2.1 - Regresión lineal
##### 4.3.2.2.1 - ????
##### 4.3.2.2.3 - Comparativa de modelos





******
# 5- Representación de los resultados
******

******
# 6- Resolución del problema
******
